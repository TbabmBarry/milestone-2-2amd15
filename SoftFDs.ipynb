{"cells":[{"cell_type":"code","source":["import time\nimport copy\nimport hashlib\nfrom operator import add\nfrom functools import reduce\nfrom pyspark.sql import SparkSession"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ad81d60-497e-483e-9e0c-621d17964b1f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark = SparkSession.builder.getOrCreate()\nspark.conf.set('spark.sql.repl.eagerEval.enabled', True)\nsc=spark.sparkContext"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfcbac1f-7f7f-450c-b222-7053a42ecd89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["zeroVal1 = ([], 0)\nmergeVal1 = (lambda aggregated, el: (aggregated[0] + [el[0]], aggregated[1] + el[1]))    \nmergeComb1 = (lambda agg1,agg2:agg1+agg2)\ndef onebyte_hash(s):\n    return int(hashlib.sha1(s.encode(\"utf-8\")).hexdigest(), 16) % (10 ** 8)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58d09996-4786-42c3-b32b-010afdd88f1b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def generate_computational_graph(RHS, schema):\n    \"\"\"\n    Output\n    ----------\n    A dictionary where\n    key: level\n    value: list of current level's candidates, candidates are in the format of set\n    -----\n\n    \"\"\"\n    computational_graph=dict()\n    for level in range(3):\n        #use brute force to generate candidates for each level\n        computational_graph[level]=[]\n        if level== 0:\n            for attribute  in schema:\n                if attribute !=RHS:\n                    computational_graph[level].append(set([attribute]))\n\n        else:\n            for element1 in computational_graph[level-1]:\n                for element2 in computational_graph[0]:\n                    newelement = element1.union(element2)\n                    if newelement not in computational_graph[level]:\n                        if len(newelement)==level+1:\n                            computational_graph[level].append(newelement)    \n\n    return computational_graph\ndef get_candidates(level, computational_graph):\n    return computational_graph[level]\ndef prune_graph(level,current_level_result,computational_graph):\n    \"\"\"\n    Input\n    -------\n    current_level_result: (soft/delta) functional dependencies discovered by algorithm, data structure: a list of candidates where candidates are in the format of sets\n    computational_graph: A dict where key:level value: list of current level's candidates, candidates are in the format of set\n\n    Output\n    -------\n    A pruned computational graph\n    \"\"\"\n    # Candidates are pruned because minimal FD are already discovered\n\n    # prune candidates after this level by verifying whether the next level has previous level's candidates as subset\n    new_computational_graph = copy.deepcopy(computational_graph)\n    while level<2:\n        level+=1\n        for LHS in current_level_result:\n            for candidate in computational_graph[level]:\n                if LHS.issubset(candidate):\n                    if candidate in new_computational_graph[level]:\n                        new_computational_graph[level].remove(candidate)\n\n\n    return new_computational_graph\ndef transform_res(FDs):\n    \"\"\"\n    Parameters\n    --------------\n    FDs: a list of (soft/delta) functional dependencies, where elements are tuples(LHS,RHS), LHS is in the format of set\n\n    Output\n    ---------\n    current_level_result: a dictionary where key: RHS value: a list of LHS where candidates are in the form of sets\n    \"\"\"\n\n    current_level_result=dict()\n    for (LHS,RHS) in FDs:\n        if RHS not in current_level_result.keys():\n            current_level_result[RHS]=[]\n\n        current_level_result[RHS].append(LHS)\n\n    return current_level_result"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbf705a5-670b-4ee4-b40c-654003b05f6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def onebyte_hash(s):\n    return int(hashlib.sha1(s.encode(\"utf-8\")).hexdigest(), 16) % (10 ** 8)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"30d7844d-00d0-4cd4-9e17-c7272eab614a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def find_softFDs_pairs(level, df,current_level_candidates):\n  softFDs = []\n  candidates_num = 0\n  for RHS in current_level_candidates.keys():\n      for LHS in current_level_candidates[RHS]:\n        candidates_num += 1\n  i = 0\n  array_rdds = [spark.sparkContext.emptyRDD()] * candidates_num\n  for RHS in current_level_candidates.keys():\n      for LHS in current_level_candidates[RHS]:\n          rddt=df.rdd.map(lambda x: (*LHS, RHS, tuple(x[idx] for idx in list(map(lambda y: schema.index(y),LHS))), x[schema.index(RHS)]))\n          array_rdds[i] = array_rdds[i].union(rddt)\n          i += 1\n\n  if len(array_rdds) >= 1:\n    rdds = sc.union(array_rdds)\n  else:\n    rdds = spark.sparkContext.emptyRDD()\n  rdds = rdds.map(lambda x: (x,1))\\\n            .coalesce(4)\\\n            .reduceByKey(add)\\\n            .map(lambda x: ((x[0][:-1]), (x[1], x[1])))\\\n            .partitionBy(4, lambda tup: onebyte_hash(''.join(tup[0])))\\\n            .aggregateByKey(zeroVal1,mergeVal1,mergeComb1)\\\n            .map(lambda x: ((x[0][:-1]), list(map(lambda r: r / x[1][1],x[1][0]))))\\\n            .map(lambda x: (x[0], any(p >= 0.8 for p in x[1])))\\\n            .coalesce(4)\\\n            .reduceByKey(lambda x, y: x * y)\\\n            .filter(lambda x: x[1] == 1)\\\n            .map(lambda x:(*x[0][:level],x[0][level]))\\\n            .distinct()\\\n            .collect()\n            \n            \n  for item in rdds:\n      softFDs.append(({*item[:-1]},item[-1]))\n\n  return softFDs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8acfb8e4-af4a-4321-baad-34e1a6c14725"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def controller(df, func):\n  \"\"\"\n  A control flow function\n\n  Parameters\n  -----------\n  func: (soft/delta) Functional Discovery functions\n  df: dataframe\n\n  Output\n  ------\n  (soft/delta) Functional Dependencies\n  \"\"\"  \n  # Initialization: Generate computational graph for each attribute which will be on RHS\n  schema = df.columns\n  computational_graph=dict()\n  FDs=[]\n  for RHS in schema:\n    computational_graph[RHS]=generate_computational_graph(RHS,schema)\n\n  for level in range(3):\n    # Get current level candidates\n    current_level_candidates=dict()\n    for RHS in computational_graph.keys():\n      current_level_candidates[RHS] = get_candidates(level,computational_graph[RHS])\n\n    # Use current_level candidates as an input to FD-functions for each level, func will return discovered (soft/delta)functional dependencies\n    tFDs = func(level,df,current_level_candidates)\n    FDs.extend(tFDs)\n    #Transform res into a dictionary where key: RHS value: a list of LHS where candidates are in the form of sets\n    current_level_result = transform_res(tFDs)\n\n    # Prune graphs according to feedback of FD-functions\n    for RHS in computational_graph.keys():\n      if RHS in current_level_result.keys():\n        computational_graph[RHS]=prune_graph(level, current_level_result[RHS],computational_graph[RHS])\n\n\n  return FDs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4259be94-6e1f-4074-b8ef-7b14dbbbde66"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["computational_graph=dict()\ndf_10000 = spark.sql(\"SELECT * FROM _2018_01_bme280sof_3_csv limit 10000\")\ndf_10000=df_10000.drop('_c0')\nschema = df_10000.columns"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e091fe5d-eb89-437a-a869-d086c3b65781"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["start_time = time.time()\n# softFDs = find_softFDs_pairs(1, df_10000, current_level_candidates)\nsoftFDs = controller(df_10000, find_softFDs_pairs)\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\nprint(softFDs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de90546d-5c32-44ae-82f2-138171333577"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">--- 192.77763414382935 seconds ---\n[(set(), &#39;location&#39;), (set(), &#39;sensor_id&#39;), ({&#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;location&#39;}, &#39;temperature&#39;), ({&#39;location&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;timestamp&#39;), ({&#39;timestamp&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;}, &#39;humidity&#39;), ({&#39;humidity&#39;}, &#39;location&#39;), ({&#39;location&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;}, &#39;sensor_id&#39;), ({&#39;sensor_id&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;}, &#39;location&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;humidity&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;humidity&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;humidity&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;location&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;location&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;lat&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;location&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;humidity&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--- 192.77763414382935 seconds ---\n[(set(), &#39;location&#39;), (set(), &#39;sensor_id&#39;), ({&#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;location&#39;}, &#39;temperature&#39;), ({&#39;location&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;timestamp&#39;), ({&#39;timestamp&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;}, &#39;humidity&#39;), ({&#39;humidity&#39;}, &#39;location&#39;), ({&#39;location&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;}, &#39;sensor_id&#39;), ({&#39;sensor_id&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;}, &#39;location&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;humidity&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;humidity&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;humidity&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;location&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;location&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;lat&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;location&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;timestamp&#39;}, &#39;humidity&#39;)]\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"SoftFD","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4109690948093112}},"nbformat":4,"nbformat_minor":0}
