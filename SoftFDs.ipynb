{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed46426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:14.443112Z",
     "start_time": "2021-06-01T21:28:14.427869Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4156fdf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:21.015356Z",
     "start_time": "2021-06-01T21:28:15.420886Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "from pyspark.sql import SparkSession\n",
    "conf = ps.SparkConf().setMaster('local').setAppName(\"softFD\")\n",
    "sc = ps.SparkContext('local[4]', '', conf=conf) # uses 4 cores on your local machine\n",
    "spark=SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e351bb9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.182004Z",
     "start_time": "2021-06-01T21:28:21.020358Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = spark.read.format(\"csv\").option(\"header\", \"true\").load('./data/2018-01_bme280sof.csv')\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load('./data/ToyTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a16dd305",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.213970Z",
     "start_time": "2021-06-01T21:28:25.185965Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop('_c0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce6a448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.515963Z",
     "start_time": "2021-06-01T21:28:25.217967Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.createOrReplaceTempView(\"sofia\")\n",
    "df.createOrReplaceTempView(\"toy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91f5341",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.596004Z",
     "start_time": "2021-06-01T21:28:25.518976Z"
    }
   },
   "outputs": [],
   "source": [
    "# small_df = spark.sql(\"select * from sofia limit 1000\")\n",
    "toy_df = spark.sql(\"select * from toy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dde14198",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.659961Z",
     "start_time": "2021-06-01T21:28:25.598967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I1', 'I2', 'S1', 'S2', 'N1', 'N2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import add\n",
    "from functools import reduce\n",
    "# schema = small_df.columns\n",
    "schema = toy_df.columns\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f8c063f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.674963Z",
     "start_time": "2021-06-01T21:28:25.662963Z"
    }
   },
   "outputs": [],
   "source": [
    "LHS = {'I1'}\n",
    "RHS = 'S2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf0742d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.690000Z",
     "start_time": "2021-06-01T21:28:25.678965Z"
    }
   },
   "outputs": [],
   "source": [
    "zeroVal1 = ([], 0)\n",
    "mergeVal1 = (lambda aggregated, el: (aggregated[0] + [el[0]], aggregated[1] + el[1]))    \n",
    "mergeComb1 = (lambda agg1,agg2:agg1+agg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ecf2b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.705963Z",
     "start_time": "2021-06-01T21:28:25.693965Z"
    }
   },
   "outputs": [],
   "source": [
    "zeroVal2 = ([], [], [])\n",
    "mergeVal2 = (lambda aggregated, el: (aggregated[0] + [el[0]], aggregated[1] + [el[1]], aggregated[2] + [el[2]]))    \n",
    "mergeComb2 = (lambda agg1,agg2:agg1+agg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf975997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:25.720967Z",
     "start_time": "2021-06-01T21:28:25.709967Z"
    }
   },
   "outputs": [],
   "source": [
    "zeroVal3 = ([], [])\n",
    "mergeVal3 = (lambda aggregated, el: (aggregated[0] + [el[0]], aggregated[1] + [el[1]]))    \n",
    "mergeComb3 = (lambda agg1,agg2:agg1+agg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91b47f94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:28.813886Z",
     "start_time": "2021-06-01T21:28:25.724968Z"
    }
   },
   "outputs": [],
   "source": [
    "# map and reduce into a five-tuple rdd\n",
    "rdd1 = toy_df.rdd.map(lambda x: (*LHS, RHS, tuple(x[idx] for idx in list(map(lambda y: schema.index(y),LHS))), x[schema.index(RHS)]))\\\n",
    "    .map(lambda tpe: (tpe,1)).reduceByKey(add) \\\n",
    "    .map(lambda x: ((x[0][:-1]), ((x[0][-1], x[1]), x[1])))\\\n",
    "    .aggregateByKey(zeroVal1,mergeVal1,mergeComb1).map(lambda x: ((x[0]), list(map(lambda r: round(r[1] / x[1][1], 3),x[1][0]))))\\\n",
    "    .map(lambda x: ((x[0]), 1 - reduce(lambda p1, p2:p1+p2,list(map(lambda p: p*(1-p), x[1])))))\\\n",
    "    .map(lambda x: ((x[0][:-1]), (x[0][-1], x[1]))).aggregateByKey(zeroVal3,mergeVal3,mergeComb3).filter(lambda tup: all(t >= 0.8 for t in tup[1][1]))\\\n",
    "    .map(lambda tup: tup[0]).collect()\n",
    "    \n",
    "# rdd2 = rdd1.map(lambda x: ((x[0][:-1]), ((x[0][-1], x[1]), x[1]))).aggregateByKey(zeroVal1,mergeVal1,mergeComb1).map(lambda x: ((x[0]), list(map(lambda r: round(r[1] / x[1][1], 3),x[1][0])))).collect()\n",
    "# rdd2 = rdd1.map(lambda x: ((x[0][:-1]), ((x[0][-1], x[1]), x[1]))).aggregateByKey(zeroVal1,mergeVal1,mergeComb1).map(lambda x: ((x[0]), (list(map(lambda r: (r[0], round(r[1] / x[1][1], 3)),x[1][0])), x[1][1]))).collect()\n",
    "# rdd2 = rdd1.map(lambda x: ((x[0][:-1]), ((x[0][-1], x[1]), x[1]))).aggregateByKey(zeroVal1,mergeVal1,mergeComb1).map(lambda x: ((x[0][:-1]), (x[0][-1], *x[1]))).aggregateByKey(zeroVal2,mergeVal2,mergeComb2).collect()\n",
    "for line in rdd1:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad43c5dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:28.828886Z",
     "start_time": "2021-06-01T21:28:28.815887Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_computational_graph(RHS, schema):\n",
    "    \"\"\"\n",
    "    Output\n",
    "    ----------\n",
    "    A dictionary where\n",
    "    key: level\n",
    "    value: list of current level's candidates, candidates are in the format of set\n",
    "    -----\n",
    "\n",
    "    \"\"\"\n",
    "    computational_graph=dict()\n",
    "    for level in range(3):\n",
    "        #use brute force to generate candidates for each level\n",
    "        computational_graph[level]=[]\n",
    "        if level== 0:\n",
    "            for attribute  in schema:\n",
    "                if attribute !=RHS:\n",
    "                    computational_graph[level].append(set([attribute]))\n",
    "\n",
    "        else:\n",
    "            for element1 in computational_graph[level-1]:\n",
    "                for element2 in computational_graph[0]:\n",
    "                    newelement = element1.union(element2)\n",
    "                    if newelement not in computational_graph[level]:\n",
    "                        if len(newelement)==level+1:\n",
    "                            computational_graph[level].append(newelement)    \n",
    "\n",
    "    return computational_graph\n",
    "def get_candidates(level, computational_graph):\n",
    "    return computational_graph[level]\n",
    "def prune_graph(level,current_level_result,computational_graph):\n",
    "    \"\"\"\n",
    "    Input\n",
    "    -------\n",
    "    current_level_result: (soft/delta) functional dependencies discovered by algorithm, data structure: a list of candidates where candidates are in the format of sets\n",
    "    computational_graph: A dict where key:level value: list of current level's candidates, candidates are in the format of set\n",
    "\n",
    "    Output\n",
    "    -------\n",
    "    A pruned computational graph\n",
    "    \"\"\"\n",
    "    # Candidates are pruned because minimal FD are already discovered\n",
    "\n",
    "    # prune candidates after this level by verifying whether the next level has previous level's candidates as subset\n",
    "    new_computational_graph = copy.deepcopy(computational_graph)\n",
    "    while level<2:\n",
    "        level+=1\n",
    "        for LHS in current_level_result:\n",
    "            for candidate in computational_graph[level]:\n",
    "                if LHS.issubset(candidate):\n",
    "                    if candidate in new_computational_graph[level]:\n",
    "                        new_computational_graph[level].remove(candidate)\n",
    "\n",
    "\n",
    "    return new_computational_graph\n",
    "def transform_res(FDs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    --------------\n",
    "    FDs: a list of (soft/delta) functional dependencies, where elements are tuples(LHS,RHS), LHS is in the format of set\n",
    "\n",
    "    Output\n",
    "    ---------\n",
    "    current_level_result: a dictionary where key: RHS value: a list of LHS where candidates are in the form of sets\n",
    "    \"\"\"\n",
    "\n",
    "    current_level_result=dict()\n",
    "    for (LHS,RHS) in FDs:\n",
    "        if RHS not in current_level_result.keys():\n",
    "            current_level_result[RHS]=[]\n",
    "\n",
    "        current_level_result[RHS].append(LHS)\n",
    "\n",
    "    return current_level_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86e70732",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:28.858885Z",
     "start_time": "2021-06-01T21:28:28.830887Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_softFDs_pairs(level, df,current_level_candidates):\n",
    "    softFDs=[]\n",
    "    rdds=spark.sparkContext.emptyRDD()\n",
    "    for RHS in current_level_candidates.keys():\n",
    "        for LHS in current_level_candidates[RHS]:\n",
    "            rddt=df.rdd.map(lambda x: (*LHS, RHS, tuple(x[idx] for idx in list(map(lambda y: schema.index(y),LHS))), x[schema.index(RHS)]))\n",
    "            rdds=rdds.union(rddt)\n",
    "    \n",
    "    rdds = rdds.map(lambda tpe: (tpe,1)).reduceByKey(add)\\\n",
    "                .map(lambda x: ((x[0][:-1]), ((x[0][-1], x[1]), x[1])))\\\n",
    "                .repartition(1)\\\n",
    "                .aggregateByKey(zeroVal1,mergeVal1,mergeComb1)\\\n",
    "                .map(lambda x: ((x[0]), list(map(lambda r: round(r[1] / x[1][1], 3),x[1][0]))))\\\n",
    "                .map(lambda x: ((x[0]), 1 - reduce(lambda p1, p2:p1+p2,list(map(lambda p: p*(1-p), x[1])))))\\\n",
    "                .map(lambda x: ((x[0][:-1]), (x[0][-1], x[1]))).aggregateByKey(zeroVal3,mergeVal3,mergeComb3)\\\n",
    "                .filter(lambda tup: all(t >= 0.8 for t in tup[1][1]))\\\n",
    "                .map(lambda x:(*x[0][:level],x[0][level]))\n",
    "                \n",
    "    for item in rdds.toLocalIterator():\n",
    "        softFDs.append(({*item[:-1]},item[-1]))\n",
    "\n",
    "    return softFDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad88a8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:28.874903Z",
     "start_time": "2021-06-01T21:28:28.860888Z"
    }
   },
   "outputs": [],
   "source": [
    "computational_graph=dict()\n",
    "for RHS in schema:\n",
    "    computational_graph[RHS]=generate_computational_graph(RHS,schema)\n",
    "\n",
    "#Define current_level_candidates\n",
    "current_level_candidates=dict()\n",
    "\n",
    "for RHS in schema:\n",
    "    current_level_candidates[RHS] = get_candidates(0,computational_graph[RHS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b31a834",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:28:28.890888Z",
     "start_time": "2021-06-01T21:28:28.876887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I1': [{'I2'}, {'S1'}, {'S2'}, {'N1'}, {'N2'}],\n",
       " 'I2': [{'I1'}, {'S1'}, {'S2'}, {'N1'}, {'N2'}],\n",
       " 'S1': [{'I1'}, {'I2'}, {'S2'}, {'N1'}, {'N2'}],\n",
       " 'S2': [{'I1'}, {'I2'}, {'S1'}, {'N1'}, {'N2'}],\n",
       " 'N1': [{'I1'}, {'I2'}, {'S1'}, {'S2'}, {'N2'}],\n",
       " 'N2': [{'I1'}, {'I2'}, {'S1'}, {'S2'}, {'N1'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_level_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb563161",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T21:29:25.382739Z",
     "start_time": "2021-06-01T21:28:28.892887Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 56.48285126686096 seconds ---\n",
      "[({'N2'}, 'I1'), ({'S1'}, 'I1'), ({'N1'}, 'I1'), ({'N2'}, 'S1'), ({'N1'}, 'S1'), ({'N2'}, 'N1'), ({'I1'}, 'S1')]\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "softFDs = find_softFDs_pairs(1, toy_df, current_level_candidates)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "print(softFDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37253aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
