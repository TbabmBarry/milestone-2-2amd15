{"cells":[{"cell_type":"code","source":["import copy\nimport time"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ad81d60-497e-483e-9e0c-621d17964b1f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\nspark.conf.set('spark.sql.repl.eagerEval.enabled', True)\nsc=spark.sparkContext"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cfcbac1f-7f7f-450c-b222-7053a42ecd89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Get yourself Familiar with Key-Value Pairs in Pyspark"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16a62c2d-41a3-47ef-83b6-2c9011c85011"}}},{"cell_type":"code","source":["#Play with this if you are not familiar with mapReduce in Pyspark :)\n\ndff = spark.sql(\"SELECT * FROM _2018_01_bme280sof_1_csv limit 5\")\ndff=dff.drop('_c0')\nschema=dff.columns\n\nrdd1=dff.rdd.map(lambda x: ({schema[0],schema[1]},schema[2],(x[0],x[1]),x[2]))\nrdd2=dff.rdd.map(lambda x: ({schema[1],schema[2]},schema[3],(x[1],x[2]),x[3]))\n\nrdd3=rdd1.union(rdd2)\nrdd3=rdd3.map(lambda x:((x[0],x[1],x[2],x[3]),1))\n# rdd3=rdd3.reduceByKey(lambda x,y:x)\ni=0\nfor w in rdd3.toLocalIterator():\n  i+=1\n  print(w)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8a504aab-2180-4fa8-9d6b-9551e71e4807"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"dff","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"sensor_id","nullable":true,"type":"integer"},{"metadata":{},"name":"location","nullable":true,"type":"integer"},{"metadata":{},"name":"lat","nullable":true,"type":"double"},{"metadata":{},"name":"lon","nullable":true,"type":"double"},{"metadata":{},"name":"timestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"pressure","nullable":true,"type":"float"},{"metadata":{},"name":"temperature","nullable":true,"type":"float"},{"metadata":{},"name":"humidity","nullable":true,"type":"float"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (2294, 1155), 42.645), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (7111, 3597), 42.648999999999994), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (5917, 2984), 42.656000000000006), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (6417, 3241), 42.68899999999999), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (6088, 3072), 42.687), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (1155, 42.645), 23.265), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (3597, 42.648999999999994), 23.385), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (2984, 42.656000000000006), 23.301), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (3241, 42.68899999999999), 23.265), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (3072, 42.687), 23.354), 1)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (2294, 1155), 42.645), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (7111, 3597), 42.648999999999994), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (5917, 2984), 42.656000000000006), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (6417, 3241), 42.68899999999999), 1)\n(({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;, (6088, 3072), 42.687), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (1155, 42.645), 23.265), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (3597, 42.648999999999994), 23.385), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (2984, 42.656000000000006), 23.301), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (3241, 42.68899999999999), 23.265), 1)\n(({&#39;lat&#39;, &#39;location&#39;}, &#39;lon&#39;, (3072, 42.687), 23.354), 1)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Play with this if you are not familiar with mapReduce in Pyspark :)\n\n# words = sc.parallelize([(({\"Hadoop\"},1),1),(({\"is\"},1),1),(({\"good\"},1),1), (({\"Spark\"},1),1),(({\"is\"},1),1),(({\"fast\"},1),1),(({\"Spark\"},1),1),(({\"is\"},1),1),(({\"better\"},1),1)])\n\n# words = sc.parallelize([({\"Hadoop\"},'1','2'),({\"is\"},'1','1'),({\"good\"},'1','1'), ({\"Spark\"},'1','1'),({\"is\"},'1','2'),({\"fast\"},'1','1'),({\"Spark\"},'1','1'),({\"is\"},'1','1'),({\"better\"},'1','1')])\n\nwords = sc.parallelize([(\"Hadoop\",'1',2),(\"is\",'1',1),(\"good\",'1',1), (\"Spark\",'1',1),(\"is\",'2',1),(\"fast\",'1',1),(\"Spark\",'1',1),(\"is\",'1',1),(\"better\",'1',1)])\n\nwords1 = words.map(lambda x: ((x[0],x[1],x[2]),1))\n\n#remap\nword_re=words1.map(lambda x:(x[0],x[1][0],x[1][1]))\n\nwords2 = words1.reduceByKey(lambda x,y: x)\n\n# words2 = words1.aggregateByKey(10,(lambda a,b:1 if(a==b) else 0),(lambda a,b:1 if(a==b) else 0))\n\n# words2 = words1.reduceByKey(lambda a,b:a+b)\n# words3 = words2.aggregateByKey()\n\n#remap\nprint(\"before\")\nfor w in words1.toLocalIterator():\n  print(w)\n  \nprint(\"after\")\nfor w in words2.toLocalIterator():\n  print(w)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"faa044f8-dccf-4da8-83eb-1908db0f0628"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">before\n((&#39;Hadoop&#39;, &#39;1&#39;, 2), 1)\n((&#39;is&#39;, &#39;1&#39;, 1), 1)\n((&#39;good&#39;, &#39;1&#39;, 1), 1)\n((&#39;Spark&#39;, &#39;1&#39;, 1), 1)\n((&#39;is&#39;, &#39;2&#39;, 1), 1)\n((&#39;fast&#39;, &#39;1&#39;, 1), 1)\n((&#39;Spark&#39;, &#39;1&#39;, 1), 1)\n((&#39;is&#39;, &#39;1&#39;, 1), 1)\n((&#39;better&#39;, &#39;1&#39;, 1), 1)\nafter\n((&#39;Hadoop&#39;, &#39;1&#39;, 2), 1)\n((&#39;is&#39;, &#39;1&#39;, 1), 1)\n((&#39;is&#39;, &#39;2&#39;, 1), 1)\n((&#39;fast&#39;, &#39;1&#39;, 1), 1)\n((&#39;better&#39;, &#39;1&#39;, 1), 1)\n((&#39;Spark&#39;, &#39;1&#39;, 1), 1)\n((&#39;good&#39;, &#39;1&#39;, 1), 1)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">before\n((&#39;Hadoop&#39;, &#39;1&#39;, 2), 1)\n((&#39;is&#39;, &#39;1&#39;, 1), 1)\n((&#39;good&#39;, &#39;1&#39;, 1), 1)\n((&#39;Spark&#39;, &#39;1&#39;, 1), 1)\n((&#39;is&#39;, &#39;2&#39;, 1), 1)\n((&#39;fast&#39;, &#39;1&#39;, 1), 1)\n((&#39;Spark&#39;, &#39;1&#39;, 1), 1)\n((&#39;is&#39;, &#39;1&#39;, 1), 1)\n((&#39;better&#39;, &#39;1&#39;, 1), 1)\nafter\n((&#39;Hadoop&#39;, &#39;1&#39;, 2), 1)\n((&#39;is&#39;, &#39;1&#39;, 1), 1)\n((&#39;is&#39;, &#39;2&#39;, 1), 1)\n((&#39;fast&#39;, &#39;1&#39;, 1), 1)\n((&#39;better&#39;, &#39;1&#39;, 1), 1)\n((&#39;Spark&#39;, &#39;1&#39;, 1), 1)\n((&#39;good&#39;, &#39;1&#39;, 1), 1)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Define Controller"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"74410fa3-d343-4f07-85a1-3c755703427b"}}},{"cell_type":"code","source":["def generate_computational_graph(RHS, schema):\n  \"\"\"\n  Output\n  ----------\n  A dictionary where\n  key: level\n  value: list of current level's candidates, candidates are in the format of set\n  -----\n  \n  \"\"\"\n  computational_graph=dict()\n  for level in range(3):\n    #use brute force to generate candidates for each level\n    computational_graph[level]=[]\n    if level== 0:\n      for attribute  in schema:\n        if attribute !=RHS:\n          computational_graph[level].append(set([attribute]))\n        \n    else:\n      for element1 in computational_graph[level-1]:\n        for element2 in computational_graph[0]:\n          newelement = element1.union(element2)\n          if newelement not in computational_graph[level]:\n            if len(newelement)==level+1:\n              computational_graph[level].append(newelement)    \n  \n  return computational_graph"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"16cf6b82-ba78-4f9d-88c8-19ae0444886c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def get_candidates(level, computational_graph):\n  return computational_graph[level]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5c2171a5-a983-4478-bf3a-3b1bb7099e63"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def prune_graph(level,current_level_result,computational_graph):\n  \"\"\"\n  Input\n  -------\n  current_level_result: (soft/delta) functional dependencies discovered by algorithm, data structure: a list of candidates where candidates are in the format of sets\n  computational_graph: A dict where key:level value: list of current level's candidates, candidates are in the format of set\n  \n  Output\n  -------\n  A pruned computational graph\n  \"\"\"\n  # Candidates are pruned because minimal FD are already discovered\n  \n  # prune candidates after this level by verifying whether the next level has previous level's candidates as subset\n  new_computational_graph = copy.deepcopy(computational_graph)\n  while level<2:\n    level+=1\n    for LHS in current_level_result:\n      for candidate in computational_graph[level]:\n        if LHS.issubset(candidate):\n          if candidate in new_computational_graph[level]:\n            new_computational_graph[level].remove(candidate)\n              \n          \n  return new_computational_graph"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"58d09996-4786-42c3-b32b-010afdd88f1b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def transform_res(FDs):\n  \"\"\"\n  Parameters\n  --------------\n  FDs: a list of (soft/delta) functional dependencies, where elements are tuples(LHS,RHS), LHS is in the format of set\n  \n  Output\n  ---------\n  current_level_result: a dictionary where key: RHS value: a list of LHS where candidates are in the form of sets\n  \"\"\"\n  \n  current_level_result=dict()\n  for (LHS,RHS) in FDs:\n    if RHS not in current_level_result.keys():\n      current_level_result[RHS]=[]\n    \n    current_level_result[RHS].append(LHS)\n    \n  return current_level_result"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7aeca4e1-9f9b-49b1-8e09-4f5912773715"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def controller(df, func):\n  \"\"\"\n  A control flow function\n\n  Parameters\n  -----------\n  func: (soft/delta) Functional Discovery functions\n  df: dataframe\n  \n  Output\n  ------\n  (soft/delta) Functional Dependencies\n  \"\"\"  \n  # Initialization: Generate computational graph for each attribute which will be on RHS\n  schema = df.columns\n  computational_graph=dict()\n  FDs=[]\n  for RHS in schema:\n    computational_graph[RHS]=generate_computational_graph(RHS,schema)\n\n  for level in range(3):\n    # Get current level candidates\n    current_level_candidates=dict()\n    for RHS in computational_graph.keys():\n      current_level_candidates[RHS] = get_candidates(level,computational_graph[RHS])\n    \n    # Use current_level candidates as an input to FD-functions for each level, func will return discovered (soft/delta)functional dependencies\n    tFDs = func(level,df,current_level_candidates)\n#     print(tFDs)\n    FDs.extend(tFDs)\n    #Transform res into a dictionary where key: RHS value: a list of LHS where candidates are in the form of sets\n    current_level_result = transform_res(tFDs)\n#     print(current_level_result)\n    \n    # Prune graphs according to feedback of FD-functions\n#     print(f\"level:{level}, computatioanl_graph_key:{computational_graph.keys()},current_level_result_key:{current_level_result.keys()}\")\n    for RHS in computational_graph.keys():\n      if RHS in current_level_result.keys():\n        computational_graph[RHS]=prune_graph(level, current_level_result[RHS],computational_graph[RHS])\n    \n  \n  return FDs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e604c263-6438-4dad-84e3-66ff2c04830c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Define FD Functions"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"11279043-ee96-4698-8317-82b3dd1007d0"}}},{"cell_type":"code","source":["# PAST FUNCTION, WHICH IS ABANDONED BY GROUP DECISION\n\n# def find_FDs_sql(df,current_level_candidates):\n#   \"\"\"\n#   Parameters\n#   -------------\n#   df: dataframe\n#   current_level_candidates: A dictionary where key:RHS value: a list of LHS, LHS are in a set format\n  \n#   Output\n#   ---------\n#   A list of discovered functional dependencies where elements are tuples(LHS,RHS)\n#   \"\"\"\n  \n#   schema = df.columns\n#   FDs=[]\n#   i=0\n#   for RHS in current_level_candidates.keys():\n#     for LHS in current_level_candidates[RHS]:\n#       i+=1\n# #       sqlstring='SELECT '+f'{\", \".join(f\"{attribute}\" for attribute in LHS)}'+f', COUNT(DISTINCT {RHS}) c'+' FROM _2018_01_bme280sof_1_csv GROUP BY '+f'{\", \".join(f\"{attribute}\" for attribute in LHS)}'+ ' HAVING c>1'\n#       sqlstring='SELECT '+f'{\", \".join(f\"{attribute}\" for attribute in LHS)}'+f', COUNT(DISTINCT {RHS}) c'+' FROM toytable_csv GROUP BY '+f'{\", \".join(f\"{attribute}\" for attribute in LHS)}'+ ' HAVING c>1'\n\n#       res = spark.sql(sqlstring).count()\n#       if(res==0):\n#         FDs.append((LHS,RHS))\n    \n#   print(i)\n#   return FDs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbf705a5-670b-4ee4-b40c-654003b05f6a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["def find_FDs_pairs(level,df,current_level_candidates):\n  \"\"\"\n  Parameters\n  -------------\n  df: dataframe\n  current_level_candidates: A dictionary where key:RHS value: a list of LHS, LHS are in a set format\n  \n  Output\n  ---------\n  A list of discovered functional dependencies where elements are tuples(LHS,RHS)\n  \"\"\"\n  \n  schema = df.columns\n  FDs=[]\n  \n  #transform dataframe to rdds\n  rdds=spark.sparkContext.emptyRDD()\n  for RHS in current_level_candidates.keys():\n    for LHS in current_level_candidates[RHS]:\n      rddt=df.rdd.map(lambda x:(*LHS,RHS,*[x[schema.index(attribute)] for attribute in LHS],x[schema.index(RHS)]))\n      rdds=rdds.union(rddt)\n      \n      \n  #Implementation of architecture\n  rdds=rdds.distinct().map(lambda x:((*x[0:-2],x[-2]),1)).reduceByKey(lambda a,b:a+b).map(lambda x:((*x[0][:level],x[0][level]),x[1])).reduceByKey(lambda a,b:max(a,b)).filter(lambda x:x[1]==1).map(lambda x:(*x[0][:level],x[0][level])).distinct()\n  \n  #RDD to FDs: tuple(LHS,RHS)\n  for item in rdds.toLocalIterator():\n    FDs.append(({*item[:-1]},item[-1]))\n    \n  return FDs"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af6def4b-999a-4b9c-9dc7-d17009b9b3ec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["a=dict()\na['a']=1\na['b']={1,2}\nprint(list(a.items())[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"043f1a60-2284-425e-97c5-9df0b4887641"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">(&#39;a&#39;, 1)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">(&#39;a&#39;, 1)\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Function Sanity Check (you do not have to play with this, but play with it if you like)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"906fc803-5805-433b-8eed-511b4cf84dee"}}},{"cell_type":"code","source":["#Import toyTable\n\ndfff = spark.sql(\"SELECT * FROM toytable_csv\")\n\nschema = dfff.columns\n\n#Generate computational graph\ncomputational_graph=dict()\nfor RHS in schema:\n  computational_graph[RHS]=generate_computational_graph(RHS,schema)\n\n#Define current_level_candidates\ncurrent_level_candidates=dict()\n\n# current_level_candidates['S1'] = get_candidates(0,computational_graph['S1'])\nfor RHS in schema:\n  current_level_candidates[RHS] = get_candidates(2,computational_graph[RHS])\n  \n\nstart_time = time.time()\n\n# FDs=find_FDs_sql(dfff,current_level_candidates)\nFDss=find_FDs_pairs(dfff,current_level_candidates)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\nprint(FDss)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a3d25171-5303-4ab3-bb4a-9970ad4a4c8c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"dfff","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"I1","nullable":true,"type":"integer"},{"metadata":{},"name":"I2","nullable":true,"type":"integer"},{"metadata":{},"name":"S1","nullable":true,"type":"string"},{"metadata":{},"name":"S2","nullable":true,"type":"string"},{"metadata":{},"name":"N1","nullable":true,"type":"float"},{"metadata":{},"name":"N2","nullable":true,"type":"float"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">--- 10.177887916564941 seconds ---\n[({&#39;S2&#39;, &#39;S1&#39;, &#39;N1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N1&#39;}, &#39;I2&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;N2&#39;}, &#39;I2&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;S2&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;I1&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;I2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I1&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I1&#39;}, &#39;S1&#39;), ({&#39;S1&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;I2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N1&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I2&#39;}, &#39;S1&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S2&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S2&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S2&#39;), ({&#39;S2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;I2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S2&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S2&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S1&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--- 10.177887916564941 seconds ---\n[({&#39;S2&#39;, &#39;S1&#39;, &#39;N1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N1&#39;}, &#39;I2&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;N2&#39;}, &#39;I2&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;S2&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;I1&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;I2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I1&#39;}, &#39;I2&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I1&#39;}, &#39;S1&#39;), ({&#39;S1&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;I2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N1&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;I2&#39;}, &#39;S1&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S2&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S2&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;S1&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;N1&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;I1&#39;), ({&#39;N1&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S2&#39;), ({&#39;S2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S1&#39;), ({&#39;I2&#39;, &#39;I1&#39;, &#39;N2&#39;}, &#39;S2&#39;), ({&#39;S1&#39;, &#39;I2&#39;, &#39;N2&#39;}, &#39;S2&#39;), ({&#39;S2&#39;, &#39;I2&#39;, &#39;I1&#39;}, &#39;S1&#39;)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["i=0\nFDt=copy.deepcopy(FDss)\n\nfor FDssitem in FDss:\n  for FDsitem in FDs:\n    if(FDssitem[1]==FDsitem[1]):\n      if(FDsitem[0].issubset(FDssitem[0])):\n        if FDssitem in FDt:\n          FDt.remove(FDssitem)\n\nprint(FDt)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2c28081-420f-428b-8d20-db57b7c303c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM _2018_01_bme280sof_1_csv limit 2000\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3c2c57c5-c545-4877-b448-5a0386d4d975"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"_c0","nullable":true,"type":"integer"},{"metadata":{},"name":"sensor_id","nullable":true,"type":"integer"},{"metadata":{},"name":"location","nullable":true,"type":"integer"},{"metadata":{},"name":"lat","nullable":true,"type":"double"},{"metadata":{},"name":"lon","nullable":true,"type":"double"},{"metadata":{},"name":"timestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"pressure","nullable":true,"type":"float"},{"metadata":{},"name":"temperature","nullable":true,"type":"float"},{"metadata":{},"name":"humidity","nullable":true,"type":"float"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Function Sanity Check\ndf=df.drop('_c0')\nschema = df.columns\ncomputational_graph=dict()\nfor RHS in schema:\n  computational_graph[RHS]=generate_computational_graph(RHS,schema)\n\n# print(computational_graph['sensor_id'][2])\n\n#Transform res into a dictionary where key: RHS value: a list of LHS\ncurrent_level_result = dict()\nfor RHS in schema:\n  current_level_result[RHS] = [{'location', 'temperature'}]\n  \n# Prune graphs according to feedback of FD-functions\nfor RHS in schema:\n  computational_graph[RHS]=prune_graph(1, current_level_result[RHS],computational_graph[RHS]) \n  \n# print(computational_graph['sensor_id'][2])\n\ncurrent_level_candidates=dict()\n\ncurrent_level_candidates['sensor_id'] = get_candidates(0,computational_graph['sensor_id'])\n# for RHS in schema:\n#   current_level_candidates[RHS] = get_candidates(0,computational_graph[RHS])\n  \n\nstart_time = time.time()\n\n# FDs=find_FDs_sql(df,current_level_candidates)\nFDs=find_FDs_pairs(df,current_level_candidates)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\n\n# print(FDs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ef2ee8d0-2db7-45ba-8d94-ccef6df259d8"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"sensor_id","nullable":true,"type":"integer"},{"metadata":{},"name":"location","nullable":true,"type":"integer"},{"metadata":{},"name":"lat","nullable":true,"type":"double"},{"metadata":{},"name":"lon","nullable":true,"type":"double"},{"metadata":{},"name":"timestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"pressure","nullable":true,"type":"float"},{"metadata":{},"name":"temperature","nullable":true,"type":"float"},{"metadata":{},"name":"humidity","nullable":true,"type":"float"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">start printing\n(&#39;location&#39;, &#39;sensor_id&#39;)\n--- 3.2105870246887207 seconds ---\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">start printing\n(&#39;location&#39;, &#39;sensor_id&#39;)\n--- 3.2105870246887207 seconds ---\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["print(FDs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2ccc3534-a4ac-4f14-ad6f-d322a7f8e3ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">[({&#39;location&#39;}, &#39;sensor_id&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">[({&#39;location&#39;}, &#39;sensor_id&#39;)]\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Test on ToyTable & Dataset"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"47810ce3-1eb4-42aa-b169-02f880ba1825"}}},{"cell_type":"code","source":["#Import toyTable\n\ndff = spark.sql(\"SELECT * FROM toytable_csv\")\n  \n# Use controller  \nstart_time = time.time()\n\nFDs=controller(dff,find_FDs_pairs)\n\n# FDs=find_FDs_pairs(dfff,current_level_candidates)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\nprint(FDs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6b22ab8d-d536-42dc-93e3-eecd0f67b940"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"dff","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"I1","nullable":true,"type":"integer"},{"metadata":{},"name":"I2","nullable":true,"type":"integer"},{"metadata":{},"name":"S1","nullable":true,"type":"string"},{"metadata":{},"name":"S2","nullable":true,"type":"string"},{"metadata":{},"name":"N1","nullable":true,"type":"float"},{"metadata":{},"name":"N2","nullable":true,"type":"float"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">--- 22.090200185775757 seconds ---\n[({&#39;N1&#39;}, &#39;I2&#39;), ({&#39;S2&#39;}, &#39;N2&#39;), ({&#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;N1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;}, &#39;I2&#39;), ({&#39;N1&#39;, &#39;S1&#39;}, &#39;I2&#39;), ({&#39;I2&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;I2&#39;), ({&#39;S1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;N1&#39;}, &#39;I1&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--- 22.090200185775757 seconds ---\n[({&#39;N1&#39;}, &#39;I2&#39;), ({&#39;S2&#39;}, &#39;N2&#39;), ({&#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;N1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;N1&#39;), ({&#39;N1&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;N1&#39;}, &#39;I2&#39;), ({&#39;N1&#39;, &#39;S1&#39;}, &#39;I2&#39;), ({&#39;I2&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I1&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;I2&#39;}, &#39;I1&#39;), ({&#39;S2&#39;, &#39;S1&#39;}, &#39;I2&#39;), ({&#39;S1&#39;, &#39;I2&#39;}, &#39;N2&#39;), ({&#39;S2&#39;, &#39;N1&#39;}, &#39;I1&#39;)]\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Import toyTable\n\ndfff = spark.sql(\"SELECT * FROM _2018_01_bme280sof_1_csv limit 5\")\ndfff.drop('_c0')\n# Use controller  \nstart_time = time.time()\n\nFDs = controller(dfff,find_FDs_pairs)\n\n# FDs=find_FDs_pairs(dfff,current_level_candidates)\n\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\nprint(FDs)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9ccd369a-27b0-4035-b79b-00e217a9c7f9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"dfff","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"_c0","nullable":true,"type":"integer"},{"metadata":{},"name":"sensor_id","nullable":true,"type":"integer"},{"metadata":{},"name":"location","nullable":true,"type":"integer"},{"metadata":{},"name":"lat","nullable":true,"type":"double"},{"metadata":{},"name":"lon","nullable":true,"type":"double"},{"metadata":{},"name":"timestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"pressure","nullable":true,"type":"float"},{"metadata":{},"name":"temperature","nullable":true,"type":"float"},{"metadata":{},"name":"humidity","nullable":true,"type":"float"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">--- 37.94422006607056 seconds ---\n[(set(), &#39;sensor_id&#39;), (set(), &#39;_c0&#39;), (set(), &#39;location&#39;), (set(), &#39;pressure&#39;), (set(), &#39;lat&#39;), (set(), &#39;temperature&#39;), (set(), &#39;humidity&#39;), ({&#39;sensor_id&#39;}, &#39;location&#39;), ({&#39;lat&#39;}, &#39;pressure&#39;), ({&#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;}, &#39;humidity&#39;), ({&#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;}, &#39;_c0&#39;), ({&#39;location&#39;}, &#39;pressure&#39;), ({&#39;location&#39;}, &#39;temperature&#39;), ({&#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;}, &#39;humidity&#39;), ({&#39;lon&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;timestamp&#39;), ({&#39;lon&#39;}, &#39;sensor_id&#39;), ({&#39;lon&#39;}, &#39;location&#39;), ({&#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;location&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;}, &#39;location&#39;), ({&#39;humidity&#39;}, &#39;location&#39;), ({&#39;lon&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;}, &#39;temperature&#39;), ({&#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;}, &#39;temperature&#39;), ({&#39;location&#39;}, &#39;lat&#39;), ({&#39;lon&#39;}, &#39;humidity&#39;), ({&#39;humidity&#39;}, &#39;lat&#39;), ({&#39;lat&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;}, &#39;lat&#39;), ({&#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;location&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;location&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;location&#39;, &#39;_c0&#39;}, &#39;temperature&#39;), ({&#39;lat&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;lat&#39;), ({&#39;location&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;humidity&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;location&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;humidity&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;humidity&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;humidity&#39;), ({&#39;lon&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;location&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;location&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;lat&#39;), ({&#39;location&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;temperature&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;lat&#39;, &#39;_c0&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;humidity&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;location&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;location&#39;), ({&#39;humidity&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;humidity&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;temperature&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;humidity&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;location&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;pressure&#39;)]\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">--- 37.94422006607056 seconds ---\n[(set(), &#39;sensor_id&#39;), (set(), &#39;_c0&#39;), (set(), &#39;location&#39;), (set(), &#39;pressure&#39;), (set(), &#39;lat&#39;), (set(), &#39;temperature&#39;), (set(), &#39;humidity&#39;), ({&#39;sensor_id&#39;}, &#39;location&#39;), ({&#39;lat&#39;}, &#39;pressure&#39;), ({&#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;}, &#39;humidity&#39;), ({&#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;}, &#39;_c0&#39;), ({&#39;location&#39;}, &#39;pressure&#39;), ({&#39;location&#39;}, &#39;temperature&#39;), ({&#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;}, &#39;humidity&#39;), ({&#39;lon&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;timestamp&#39;), ({&#39;lon&#39;}, &#39;sensor_id&#39;), ({&#39;lon&#39;}, &#39;location&#39;), ({&#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;location&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;}, &#39;location&#39;), ({&#39;humidity&#39;}, &#39;location&#39;), ({&#39;lon&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;}, &#39;temperature&#39;), ({&#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;}, &#39;temperature&#39;), ({&#39;location&#39;}, &#39;lat&#39;), ({&#39;lon&#39;}, &#39;humidity&#39;), ({&#39;humidity&#39;}, &#39;lat&#39;), ({&#39;lat&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;}, &#39;lat&#39;), ({&#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;location&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;location&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;location&#39;, &#39;_c0&#39;}, &#39;temperature&#39;), ({&#39;lat&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;lat&#39;), ({&#39;location&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;lat&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;humidity&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;location&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;humidity&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;humidity&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;humidity&#39;), ({&#39;lon&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;location&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;location&#39;, &#39;lat&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;lat&#39;), ({&#39;location&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;temperature&#39;, &#39;pressure&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;location&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;temperature&#39;), ({&#39;lat&#39;, &#39;_c0&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;timestamp&#39;, &#39;humidity&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;humidity&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;location&#39;, &#39;pressure&#39;}, &#39;temperature&#39;), ({&#39;lon&#39;, &#39;humidity&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;timestamp&#39;}, &#39;location&#39;), ({&#39;humidity&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;humidity&#39;), ({&#39;lat&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;sensor_id&#39;, &#39;location&#39;}, &#39;lat&#39;), ({&#39;humidity&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;lon&#39;, &#39;location&#39;}, &#39;_c0&#39;), ({&#39;sensor_id&#39;, &#39;temperature&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;lat&#39;}, &#39;pressure&#39;), ({&#39;temperature&#39;, &#39;_c0&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;_c0&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;humidity&#39;), ({&#39;lon&#39;, &#39;lat&#39;}, &#39;location&#39;), ({&#39;timestamp&#39;, &#39;location&#39;}, &#39;temperature&#39;), ({&#39;timestamp&#39;, &#39;humidity&#39;}, &#39;pressure&#39;), ({&#39;humidity&#39;, &#39;location&#39;}, &#39;pressure&#39;), ({&#39;lon&#39;, &#39;temperature&#39;}, &#39;pressure&#39;), ({&#39;sensor_id&#39;, &#39;lat&#39;}, &#39;pressure&#39;)]\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"MileStone2BackBone","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1428048768328785}},"nbformat":4,"nbformat_minor":0}
